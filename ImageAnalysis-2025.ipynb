{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce5edb4a-7f16-4f35-b0f1-5fc7167eb371",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7cde6-9eed-475a-96ce-2b6deaa80bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import geopandas\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "\n",
    "from esda import Moran, Geary\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from libpysal.weights import Queen\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import cKDTree, Voronoi, voronoi_plot_2d,distance\n",
    "from scipy.spatial.distance import cdist\n",
    "from shapely.geometry import Point\n",
    "from skimage import restoration, data, img_as_float\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb22fc-ff86-41e9-8f7e-23507bb38e72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb8936-b44e-49b2-8b7f-15d5e2317535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Showim(image,imlistCon,showing=False,ImageSaveFolder=\"\",cmap=\"plasma\"):\n",
    "    if showing==True:\n",
    "        matplotlib.pyplot.imshow(image,cmap)\n",
    "        matplotlib.pyplot.axis('off')\n",
    "        if ImageSaveFolder != \"\":\n",
    "            matplotlib.pyplot.savefig(ImageSaveFolder+\"/\"+imlistCon.split(\"\\\\\")[-1].split(\"/\")[-1].split(\".\")[0]+\".png\")\n",
    "        matplotlib.pyplot.show()\n",
    "\n",
    "def countArray(DArray,value):\n",
    "    #DArray=labels\n",
    "    #value=ID\n",
    "    x=0\n",
    "    for x1 in range(len(DArray)):\n",
    "        for x2 in range(len(DArray[x1])):\n",
    "            if DArray[x1][x2]==value:\n",
    "                x=x+1\n",
    "    return(x)\n",
    "\n",
    "#Process image 1\n",
    "def backgroundrolling(im,rad,imlistCon,fn=0,showing=False,ImageSaveFolder=\"\"):\n",
    "    imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) #threshold\n",
    "    #print(\"Dye\")\n",
    "    #Showim(imgray,\"/Dye\"+imlistCon[fn],showing,ImageSaveFolder)\n",
    "    ####\n",
    "    background = restoration.rolling_ball(imgray, radius=rad)\n",
    "    #print(\"Background\")\n",
    "    #Showim(background,\"/backgroundDye-\"+imlistCon[fn],showing,ImageSaveFolder)\n",
    "    imgray2=imgray-background\n",
    "    imgray3=imgray-background\n",
    "    if showing==True:\n",
    "        print(\"Background subtracted\")\n",
    "        Showim(imgray2,\"/subtractedBackgroundDye-\"+imlistCon[fn],showing,ImageSaveFolder)\n",
    "    return(imgray,imgray2,imgray3)\n",
    "\n",
    "def FindLocalMax(imgray2,size_value,min_distance_value,threshold_abs_value,edge_margin=50,showing=False):\n",
    "    im = img_as_float(imgray2)\n",
    "    # image_max is the dilation of im with a 20*20 structuring element\n",
    "    # It is used within peak_local_max function\n",
    "    image_max = ndimage.maximum_filter(im, size=size_value, mode='constant')\n",
    "    # Comparison between image_max and im to find the coordinates of local maxima\n",
    "    coordinates = peak_local_max(im, min_distance=min_distance_value, threshold_abs=threshold_abs_value,exclude_border=True)\n",
    "    height, width = im.shape\n",
    "    # Filter out points near the edges (within 10 pixels)\n",
    "    coordinates = numpy.array([coord for coord in coordinates \n",
    "                                     if edge_margin <= coord[0] < height - edge_margin and \n",
    "                                        edge_margin <= coord[1] < width - edge_margin])\n",
    "    # display results\n",
    "    if showing==True:\n",
    "        print(\"coordinates peaks\")\n",
    "        matplotlib.pyplot.imshow(im, cmap=matplotlib.pyplot.cm.gray)\n",
    "        matplotlib.pyplot.plot(coordinates[:, 1], coordinates[:, 0], 'r.')\n",
    "        matplotlib.pyplot.axis('off')\n",
    "        matplotlib.pyplot.show()\n",
    "    return(image_max,coordinates)\n",
    "\n",
    "#segmentar + watershed\n",
    "def threshold(imgray2,imlistCon,fn,thr_value2,Blocksize=15,Constant=-1,edge_margin=15,filtered_image=None,showing=True,ImageSaveFolder=\"\"):\n",
    "    if showing==True:\n",
    "        print(\"thresholded image\")\n",
    "    #ret, thresh = cv2.threshold(imgray2, thr_value,thr_value2,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    imgray2 = cv2.GaussianBlur(imgray2,(5,5),0)\n",
    "    thresh = cv2.adaptiveThreshold(imgray2,thr_value2,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,Blocksize,Constant)\n",
    "    kernel = numpy.ones((3, 3), numpy.uint8)  # Kernel for dilation/erosion\n",
    "    thresh = cv2.erode(thresh, kernel, iterations=1)  # Erosion to reduce noise\n",
    "    thresh = cv2.dilate(thresh, kernel, iterations=1)  # Dilation to expand blobs\n",
    "    thresh_with_border = numpy.zeros_like(imgray2)\n",
    "    thresh_with_border[edge_margin:-edge_margin, edge_margin:-edge_margin] = thresh[edge_margin:-edge_margin, edge_margin:-edge_margin]\n",
    "    if not isinstance(filtered_image, numpy.ndarray):\n",
    "        result_image=thresh_with_border\n",
    "    else:\n",
    "        result_image = cv2.bitwise_and(filtered_image, thresh_with_border)\n",
    "    Showim(result_image,\"/thresholdDye-\"+imlistCon[fn],showing,ImageSaveFolder)\n",
    "    return(result_image)\n",
    "\n",
    "\n",
    "def coords(imlistCon,fn,thresh,coordinates,imgray3,min_thresh_counter=4,showing=True,ImageSaveFolder=\"\"):\n",
    "    # Now we want to separate the two objects in image\n",
    "    # Generate the markers as local maxima of the distance to the background\n",
    "    distance = ndimage.distance_transform_edt(thresh)\n",
    "    mask = numpy.zeros(distance.shape, dtype=bool)\n",
    "    mask[tuple(coordinates.T)] = True\n",
    "    markers, _ = ndimage.label(mask)\n",
    "    labels = watershed(-distance, markers, mask=thresh)\n",
    "    \n",
    "    # Count occurrences of each label\n",
    "    unique, counts = numpy.unique(labels, return_counts=True)\n",
    "    label_counts = dict(zip(unique, counts))\n",
    "\n",
    "    # Remove labels with less than `min_thresh_counter` pixels\n",
    "    under_thresh = {label for label, count in label_counts.items() if count < min_thresh_counter}\n",
    "    labels[numpy.isin(labels, list(under_thresh))] = 0  # Vectorized filtering\n",
    "    nlabels = len(label_counts) - len(under_thresh)\n",
    "    \n",
    "    # Get the original 'prism' colormap\n",
    "    original_cmap = matplotlib.pyplot.cm.prism\n",
    "    \n",
    "    # Create a new colormap that has black for label 0 and the rest from 'prism'\n",
    "    cmap_list = [ (0, 0, 0)] + [original_cmap(i) for i in range(1, 250)]  # Black for 0, rest from 'prism'\n",
    "    new_cmap = matplotlib.colors.ListedColormap(cmap_list)\n",
    "    if showing==True:\n",
    "        # Plot using the new colormap\n",
    "        matplotlib.pyplot.imshow(labels, cmap=new_cmap)\n",
    "        print(\"filtered watershed\")\n",
    "        Showim(labels,\"/threholdedFilteredWatershed-\"+imlistCon[fn],showing,ImageSaveFolder,cmap=new_cmap)\n",
    "    \n",
    "    # Initialize lists to hold filtered coordinates, areas, and IDs\n",
    "    Areas, IDs, filtered_coordinates,xs,ys = [], [], [],[],[]\n",
    "    contour_list = []\n",
    "    Centers,Ferets,angles=[],[],[]\n",
    "    # Iterate over coordinates to filter them based on their label\n",
    "    for n in range(len(coordinates)):\n",
    "        # Get the label at the current coordinate\n",
    "        y, x = coordinates[n] # y, x because coordinates are (row, col)\n",
    "\n",
    "        #print(\"coordinates are (\"+str(x)+\",\"+str(y)+\")\")\n",
    "        label = labels[y, x] \n",
    "        \n",
    "        # If the label is valid (not 0) and the area of the label is above the threshold\n",
    "        if label != 0 and label not in under_thresh:\n",
    "            ID=label\n",
    "            result = labels == ID\n",
    "            result = (result * 255).astype(numpy.uint8)\n",
    "            contours, _ = cv2.findContours(result, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contour_list.append(contours)\n",
    "            if 5>len(contours[0]):\n",
    "                circle = cv2.minEnclosingCircle(contours[0])\n",
    "                (xc,yc),rad = circle\n",
    "                (major,minor) = (2*rad,2*rad)\n",
    "                angle=0.0\n",
    "            else:\n",
    "                ellipse = cv2.fitEllipse(contours[0])\n",
    "                (xc,yc),(major, minor),angle = ellipse\n",
    "            if numpy.isfinite(xc) and numpy.isfinite(yc):\n",
    "                IDs.append(label)\n",
    "                Area = countArray(labels, label)\n",
    "                Areas.append(Area)\n",
    "                filtered_coordinates.append(coordinates[n])\n",
    "                ys.append(y)\n",
    "                xs.append(x)\n",
    "                Centers.append((xc,yc))\n",
    "                Ferets.append((major, minor))\n",
    "                angles.append(angle)\n",
    "                #print(\"coords :\"+str((xc,yc))+\"; ferets: \"+str((major, minor))+\" angle: \"+str(angle)) \n",
    "                #print()\n",
    "        elif label == 0:\n",
    "            continue\n",
    "    \n",
    "    #Centers=[(x, y) for x, y in Centers if numpy.isfinite(x) and numpy.isfinite(y)]\n",
    "    \n",
    "    print(\"coordinates and Threshold\")\n",
    "    matplotlib.pyplot.imshow(labels, cmap=new_cmap)\n",
    "    matplotlib.pyplot.plot(xs, ys, 'r.')\n",
    "    matplotlib.pyplot.axis('off')\n",
    "    matplotlib.pyplot.show()\n",
    "    \n",
    "    # Create a list to hold contours for each valid label\n",
    "  \n",
    "    # Optionally, show the contours on the image\n",
    "    if showing:\n",
    "        imc = imgray3.copy()\n",
    "        for contours in contour_list:\n",
    "            for contour in contours:\n",
    "                imc = cv2.drawContours(imc, [contour], -1, (1, 1, 1), 1)\n",
    "        print(\"contours\")\n",
    "        matplotlib.pyplot.imshow(imc)\n",
    "        matplotlib.pyplot.axis('off')\n",
    "        matplotlib.pyplot.show()\n",
    "        \n",
    "    return(labels,IDs,Areas,coordinates,contour_list,new_cmap,xs,ys,Centers,Ferets,angles)\n",
    "\n",
    "def TextOutput(fn,contour_list,IDs,Areas,coordinates,xs,ys,Centers,Ferets,angles,imlistCon,impath,csvSaveFolder):\n",
    "    #una vez tiene los contornos hay que hacer un ajuste con una elipse par encontrar el feret majory menor.\n",
    "    #para una elipse se ncesitan al menos 6 puntos.\n",
    "    DF=pandas.DataFrame({\"ID\":IDs,\n",
    "                         \"Xcoord\":xs,\n",
    "                         \"Ycoord\":ys,\n",
    "                         \"Center\":Centers,\n",
    "                         \"Area[px]\":Areas, \n",
    "                         \"Feret [px]\": Ferets,\n",
    "                         \"Angles\":angles})\n",
    "    os.makedirs(imlistCon[fn].replace(impath,csvSaveFolder).replace(\"\\\\\",\"/\").replace((imlistCon[fn].split(\"\\\\\"))[-1],\"\"), exist_ok=True)\n",
    "    DF.to_csv((imlistCon[fn].replace(impath,csvSaveFolder).replace(\"\\\\\",\"/\"))+\".csv\")\n",
    "    \n",
    "    return(DF)\n",
    "\n",
    "def ThreshoBlob(imgray,imlistCon,fn,thr_value2,max_area,edge_margin,showing,ImageSaveFolder):\n",
    "    if showing==True:\n",
    "        print(\"thresholded image for blob detection\")\n",
    "    blur = cv2.GaussianBlur(imgray,(5,5),0)\n",
    "    ret3,thresh = cv2.threshold(blur,thr_value2,255,cv2.THRESH_BINARY)#+cv2.THRESH_OTSU)#\n",
    "    kernel = numpy.ones((5, 5), numpy.uint8)  # Kernel for dilation/erosion\n",
    "    #thresh = cv2.erode(thresh, kernel, iterations=1)  # Erosion to reduce noise\n",
    "    #thresh = cv2.dilate(thresh, kernel, iterations=1)  # Dilation to expand blobs\n",
    "    Showim(thresh,\"/thresholdBlobs-\"+imlistCon[fn],showing,ImageSaveFolder)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    filtered_image = numpy.zeros_like(imgray)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)  # Calculate the area of the contour\n",
    "        if area > max_area:\n",
    "            cv2.drawContours(filtered_image, [contour], -1, (255), thickness=cv2.FILLED)\n",
    "    if showing==True:\n",
    "        print(\"Bigblobs to filter out\")\n",
    "    filtered_image = cv2.dilate(filtered_image, kernel, iterations=1)\n",
    "    filtered_image = cv2.bitwise_not(filtered_image)\n",
    "    thresh_with_border = numpy.zeros_like(thresh)\n",
    "    thresh_with_border[edge_margin:-edge_margin, edge_margin:-edge_margin] = filtered_image[edge_margin:-edge_margin, edge_margin:-edge_margin]\n",
    "    filtered_image=thresh_with_border\n",
    "    Showim(filtered_image, \"/filteredBlobs-\" + imlistCon[fn], showing, ImageSaveFolder)\n",
    "    \n",
    "    return(thresh, filtered_image)\n",
    "\n",
    "def AOIdetector(filtered_image,im2,imn2,edge_margin,Grain=False,showing=True,ImageSaveFolder=\"\"):\n",
    "    #Process image 2\n",
    "    im2gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY) #threshold\n",
    "    if showing == True:\n",
    "        print(\"Gray\")\n",
    "        Showim(im2gray,\"/Bright\"+imn2,showing,ImageSaveFolder)\n",
    "        print(\"thresholded image for AOI detection\")\n",
    "    blur = cv2.GaussianBlur(im2gray,(5,5),0)\n",
    "    ret3,thresh2 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)#\n",
    "    kernel = numpy.ones((5, 5), numpy.uint8)  # Kernel for dilation/erosion\n",
    "    if Grain==True:\n",
    "        thresh2 = cv2.bitwise_not(thresh2)\n",
    "    thresh_with_border = numpy.zeros_like(thresh2)\n",
    "    thresh_with_border[edge_margin:-edge_margin, edge_margin:-edge_margin] = thresh2[edge_margin:-edge_margin, edge_margin:-edge_margin]\n",
    "    thresh2=thresh_with_border\n",
    "    Showim(thresh2,\"/thresholdBright-\"+imn2,showing,ImageSaveFolder)\n",
    "    contours, _ = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    filtered_image2 = numpy.zeros_like(im2gray)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)  # Calculate the area of the contour\n",
    "        if area > max_area:\n",
    "            cv2.drawContours(filtered_image2, [contour], -1, (255), thickness=cv2.FILLED)\n",
    "    if showing==True:\n",
    "        print(\"previous filtered image\")\n",
    "    Showim(filtered_image, \"\", showing, ImageSaveFolder)\n",
    "    if showing==True:\n",
    "        print(\"AOI\")\n",
    "    #filtered_image = cv2.dilate(filtered_image, kernel, iterations=1)\n",
    "\n",
    "    filtered_image2 = cv2.bitwise_and(filtered_image2,filtered_image)\n",
    "    Showim(filtered_image2, \"/AOI-\" + imn2, showing, ImageSaveFolder)\n",
    "    \n",
    "    return(thresh2, filtered_image2)\n",
    "\n",
    "def check_image_quality(image, blur_threshold=100, contrast_threshold=50):\n",
    "\n",
    "    # 1. Check blurriness using the Laplacian variance\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    variance = laplacian.var()  # Calculate variance of the Laplacian\n",
    "    \n",
    "    # 2. Check contrast using the standard deviation of pixel intensities\n",
    "    contrast = image.std()  # Standard deviation is a measure of contrast\n",
    "\n",
    "    # Print the metrics (optional)\n",
    "    print(f\"Laplacian variance (blurriness): {variance}\")\n",
    "    print(f\"Image contrast (std deviation): {contrast}\")\n",
    "    \n",
    "    # Check if the image is blurry and low contrast\n",
    "    if variance < blur_threshold:\n",
    "        print(\"The image is too blurry.\")\n",
    "        return False\n",
    "    elif contrast < contrast_threshold:\n",
    "        print(\"The image has low contrast.\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"The image has good sharpness and contrast.\")\n",
    "        return True\n",
    "\n",
    "\n",
    "def has_been_analyzed(impath, csvSaveFolder, fn, imlistCon):\n",
    "    csv_filename = imlistCon[fn].replace(impath,csvSaveFolder).replace(\"\\\\\",\"/\")+\".csv\"\n",
    "    return(os.path.exists(csv_filename))\n",
    "\n",
    "def voronoi_diagram(centroids, save_path=None, showing=False):\n",
    "    \"\"\"\n",
    "    Create and visualize a Voronoi diagram based on a list of centroids.\n",
    "\n",
    "    Parameters:\n",
    "        centroids (list of tuples): List of (x, y) coordinates for the centroids.\n",
    "        save_path (str, optional): Path to save the Voronoi diagram image. Defaults to None.\n",
    "        show (bool, optional): If True, displays the plot. Defaults to False.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Convert centroids to numpy array for Voronoi\n",
    "    points = numpy.array(centroids)\n",
    "    try:\n",
    "        # Create the Voronoi diagram\n",
    "        vor = Voronoi(points)\n",
    "\n",
    "        # Plot the Voronoi diagram\n",
    "        fig = voronoi_plot_2d(vor, show_vertices=False, line_colors='orange', line_width=2, line_alpha=0.6)\n",
    "\n",
    "        # Optionally save the plot\n",
    "        if save_path:\n",
    "            matplotlib.pyplot.savefig(save_path)\n",
    "\n",
    "        # Show the plot\n",
    "        if showing==True:\n",
    "            matplotlib.pyplot.show()\n",
    "        else:\n",
    "            matplotlib.pyplot.close()\n",
    "    except ValueError:\n",
    "        print(\"ValueError in Voronoi generation\")\n",
    "        print(centroids)\n",
    "\n",
    "\n",
    "def ripleys_k_function(centroids, r_max=600, num_bins=100, show=False, save_path=None):\n",
    "    \"\"\"\n",
    "    Calculate and plot Ripley's K-function for a given set of points.\n",
    "\n",
    "    Parameters:\n",
    "        centroids (list of tuples): List of (x, y) coordinates for the centroids.\n",
    "        r_max (int, optional): Maximum distance for the K-function analysis. Defaults to 600.\n",
    "        num_bins (int, optional): Number of distance bins for the K-function calculation. Defaults to 100.\n",
    "        show (bool, optional): If True, displays the plot. Defaults to False.\n",
    "        save_path (str, optional): Path to save the Ripley's K-function plot. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Convert centroids to numpy array\n",
    "    points = numpy.array(centroids)\n",
    "\n",
    "    # Calculate pairwise distances between points\n",
    "    distances = cdist(points, points)\n",
    "\n",
    "    # Define r-values for the K-function calculation\n",
    "    r_values = numpy.linspace(0, r_max, num=num_bins)\n",
    "\n",
    "    # Initialize the K-values array\n",
    "    k_values = numpy.zeros(len(r_values))\n",
    "\n",
    "    # Loop through r-values to calculate K(r)\n",
    "    n = len(points)\n",
    "    for i, r in enumerate(r_values):\n",
    "        # Count the number of pairs of points that are within distance r (excluding self-pairs)\n",
    "        k_values[i] = numpy.sum(distances < r) / n\n",
    "\n",
    "    # Plot Ripley's K-function\n",
    "    matplotlib.pyplot.plot(r_values, k_values, marker='o', label=\"K(r)\")\n",
    "    matplotlib.pyplot.axline((0, 0), slope=1, color='red', linestyle='--', label=\"$K(r) = r$\")  # Reference line for random distribution\n",
    "    matplotlib.pyplot.xlabel('Distance')\n",
    "    matplotlib.pyplot.ylabel('Ripley\\'s K-function')\n",
    "    matplotlib.pyplot.legend()\n",
    "\n",
    "    # Optionally save the plot\n",
    "    if save_path:\n",
    "        matplotlib.pyplot.savefig(save_path)\n",
    "\n",
    "    # Show the plot\n",
    "    if show:\n",
    "        matplotlib.pyplot.show()\n",
    "    else:\n",
    "        matplotlib.pyplot.close()\n",
    "\n",
    "\n",
    "\n",
    "def morans_i(centroids, values):\n",
    "    \"\"\"\n",
    "    Calculate Moran's I for spatial autocorrelation.\n",
    "\n",
    "    Parameters:\n",
    "        centroids (list of tuples): List of (x, y) coordinates for the centroids.\n",
    "        values (list): List of values associated with each centroid (e.g., colony sizes).\n",
    "\n",
    "    Returns:\n",
    "        morans_i_value (float): The Moran's I value.\n",
    "        interpretation (str): Interpretation of Moran's I (Clustered, Dispersed, or Random).\n",
    "    \"\"\"\n",
    "    # Convert centroids to GeoDataFrame\n",
    "    geometry = geopandas.GeoSeries([Point(x, y) for x, y in centroids])  # Use shapely.geometry.Point here\n",
    "    gdf = geopandas.GeoDataFrame({'value': values}, geometry=geometry)\n",
    "    #gdf.set_geometry('geometry', inplace=True)\n",
    "    # Create a spatial weights matrix using Queen contiguity\n",
    "    try:\n",
    "        w = Queen.from_dataframe(gdf)\n",
    "            # Calculate Moran's I\n",
    "        moran = Moran(gdf['value'], w)\n",
    "        morans_i_value = moran.I\n",
    "\n",
    "        # Interpret Moran's I\n",
    "        if morans_i_value > 0:\n",
    "            interpretation = \"Spatial Clustering\"\n",
    "        elif morans_i_value < 0:\n",
    "            interpretation = \"Spatial Dispersion\"\n",
    "        else:\n",
    "            interpretation = \"Random Spatial Pattern\"\n",
    "    except KeyError:\n",
    "        print(gdf)\n",
    "        morans_i_value = None\n",
    "        interpretation = \"Error in Moran's calculation\"\n",
    "    return morans_i_value, interpretation\n",
    "\n",
    "def calculate_geary_c_from_centroids_and_ferets(centroids, ferets):\n",
    "    \"\"\"\n",
    "    Function to calculate Geary's C for spatial autocorrelation based on centroids and their minor Feret diameters.\n",
    "\n",
    "    Parameters:\n",
    "        centroids (list of tuples): List of (x, y) coordinates of the centroids.\n",
    "        ferets (list of tuples): List of (major, minor) Feret diameters for each centroid.\n",
    "\n",
    "    Returns:\n",
    "        Geary's C value and interpretation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the centroids and ferets lists are the same length\n",
    "        if len(centroids) != len(ferets):\n",
    "            raise ValueError(\"The number of centroids must match the number of Feret values.\")\n",
    "\n",
    "        # Create a GeoDataFrame from the centroids\n",
    "        geometry = geopandas.GeoSeries([Point(x, y) for x, y in centroids])\n",
    "        \n",
    "        # Extract the minor Feret values (second element of the tuple) as the spatial attribute\n",
    "        minor_ferets = [minor for _, minor in ferets]\n",
    "\n",
    "        # Create a GeoDataFrame with minor Feret values as the 'radius' attribute\n",
    "        gdf = geopandas.GeoDataFrame({'minor_feret': minor_ferets}, geometry=geometry)\n",
    "        gdf.set_geometry('geometry', inplace=True)\n",
    "        # Create spatial weights using Queen contiguity\n",
    "        #w = Queen.from_dataframe(gdf)\n",
    "        w = Queen(gdf)\n",
    "\n",
    "        # Calculate Geary's C for the minor Feret diameters\n",
    "        geary = Geary(gdf['minor_feret'], w)\n",
    "\n",
    "        # Interpret the Geary's C result\n",
    "        if geary.C < 0.5:\n",
    "            geary_interpretation = \"Spatial Clustering\"\n",
    "        elif geary.C > 0.5:\n",
    "            geary_interpretation = \"Spatial Dispersion\"\n",
    "        else:\n",
    "            geary_interpretation = \"Random Spatial Pattern\"\n",
    "\n",
    "        # Return the result and interpretation\n",
    "        return geary.C, geary_interpretation\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error in Geary's C calculation:\", e)\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    return numpy.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "\n",
    "# Nearest Neighbor Search using KDTree\n",
    "def nearest_neighbor_kd_tree(centroids):\n",
    "    # Build a KD-tree for fast nearest neighbor search\n",
    "    tree = cKDTree(centroids)\n",
    "\n",
    "    nearest_neighbors = []\n",
    "    for i, centroid in enumerate(centroids):\n",
    "        # Query the nearest neighbor (k=2 because the closest point is itself, so we ask for 2 neighbors)\n",
    "        dist, index = tree.query(centroid, k=2)  # k=2 to find the closest neighbor excluding itself\n",
    "        nearest_neighbors.append((i, index[1], dist[1]))  # Store the nearest neighbor's index and distance\n",
    "\n",
    "    return(nearest_neighbors)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def estadisticas(datos):\n",
    "    \"\"\"\n",
    "    Calcula el promedio, desviación estándar, número de elementos (N), \n",
    "    error estándar de la media (SEM) y número de posibles outliers en una lista de valores.\n",
    "\n",
    "    Parámetros:\n",
    "    datos (list): Lista de valores numéricos para calcular las estadísticas.\n",
    "\n",
    "    Retorna:\n",
    "    promedio (float): El promedio de los datos.\n",
    "    desviacion_estandar (float): La desviación estándar de los datos.\n",
    "    N (int): Número de elementos en la lista.\n",
    "    sem (float): Error estándar de la media.\n",
    "    num_outliers (int): Número de outliers en los datos.\n",
    "    outliers (list): Lista de los valores considerados outliers.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verificar que los datos no estén vacíos\n",
    "    if len(datos) == 0:\n",
    "        return \"La lista de datos está vacía\"\n",
    "\n",
    "    # Convertir la lista de datos en un arreglo de NumPy para facilitar los cálculos\n",
    "    datos_array = numpy.array(datos)\n",
    "\n",
    "    # Cálculos básicos\n",
    "    promedio = numpy.mean(datos_array)\n",
    "    desviacion_estandar = numpy.std(datos_array)\n",
    "    N = len(datos_array)\n",
    "    sem = desviacion_estandar / numpy.sqrt(N)\n",
    "\n",
    "    # Cálculo de posibles outliers usando el criterio del rango intercuartil (IQR)\n",
    "    Q1 = numpy.percentile(datos_array, 25)\n",
    "    Q3 = numpy.percentile(datos_array, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Definición de los límites para los outliers\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Contar el número de outliers\n",
    "    outliers = [x for x in datos_array if x < limite_inferior or x > limite_superior]\n",
    "    num_outliers = len(outliers)\n",
    "\n",
    "    # Devolver los resultados como variables separadas\n",
    "    return promedio, desviacion_estandar, N, sem, num_outliers, outliers\n",
    "\n",
    "\n",
    "def analyze_area_coverage(filtered_image, Areas):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of the analyzed area covered by colonies and the total area in pixels.\n",
    "    \n",
    "    Parameters:\n",
    "    filtered_image (ndarray): Binary (thresholded) image where the analyzed area is marked.\n",
    "    Areas (list): List of areas of individual colonies.\n",
    "    \n",
    "    Returns:\n",
    "    float: Percentage of analyzed area covered by colonies.\n",
    "    int: Total analyzed area in pixels.\n",
    "    \"\"\"\n",
    "    # Calculate the total area of colonies from the list Areas\n",
    "    total_colony_area = sum(Areas)\n",
    "    \n",
    "    # Calculate the total analyzed area in pixels (number of non-zero pixels in the filtered image)\n",
    "    analyzed_area_pixels = numpy.sum(filtered_image > 0)\n",
    "    \n",
    "    # Calculate the percentage of colonies covering the analyzed area\n",
    "    if analyzed_area_pixels > 0:\n",
    "        coverage_percentage = (total_colony_area / analyzed_area_pixels) * 100\n",
    "    else:\n",
    "        coverage_percentage = 0\n",
    "    \n",
    "    return coverage_percentage, analyzed_area_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9017d73-7470-470c-9682-d221f73885b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSingle(\n",
    "    impath,\n",
    "    labelsD,\n",
    "    labelR,\n",
    "    imlabel,\n",
    "    BadLabel,\n",
    "    ImageSaveFolder,\n",
    "    csvSaveFolder,\n",
    "    Grain,\n",
    "    blur_threshold=100, \n",
    "    contrast_threshold=50,\n",
    "    fn=0,\n",
    "    label=\"DAPI\",\n",
    "    Cond=\"\",\n",
    "    edge_margin=10,\n",
    "    rad=50,\n",
    "    thr_value2=100,\n",
    "    max_area=50*50*numpy.pi,\n",
    "    size_value=2,\n",
    "    min_distance_value=2,\n",
    "    threshold_abs_value=0.1,\n",
    "    Blocksize=15,\n",
    "    Constant=-1,\n",
    "    min_thresh_counter=4,\n",
    "    showing=True,\n",
    "    QualityCheck=False,\n",
    "    Spatial=False):\n",
    "    Conds=[]\n",
    "    for Folder in [x for x in os.listdir(impath) if os.path.isdir(os.path.join(impath,x))]:\n",
    "        Conds += [Folder]\n",
    "    imlist=[]\n",
    "    imlist2=[]\n",
    "    for (root,dirs,files) in os.walk(impath, topdown=True):\n",
    "        for file in files:\n",
    "            if not file.endswith(imlabel):\n",
    "                continue\n",
    "            if label in file:\n",
    "                imlist += [os.path.join(root,file)]\n",
    "            if labelR in file:\n",
    "                imlist2 += [os.path.join(root,file)]\n",
    "    imlistCon=[f for f in imlist if Cond in f]\n",
    "    imlist2Con=[f for f in imlist2 if Cond in f]\n",
    "    imn=imlistCon[fn]\n",
    "    im=matplotlib.pyplot.imread(imn)\n",
    "    Showim(im,imlistCon[fn],showing,ImageSaveFolder)\n",
    "    #Process image 1\n",
    "    imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) #threshold\n",
    "    if showing == True:\n",
    "        print(\"Gray\")\n",
    "        Showim(imgray,\"/Dye\"+imlistCon[fn],showing,ImageSaveFolder)\n",
    "    imgray2=imgray\n",
    "    if QualityCheck==True:\n",
    "        quality=check_image_quality(imgray2, blur_threshold, contrast_threshold)\n",
    "    else:\n",
    "        quality=True\n",
    "    if quality==True:\n",
    "        imgray,imgray2,imgray3=backgroundrolling(im,rad,imlistCon,fn,showing,ImageSaveFolder=\"\")\n",
    "        thresh,filtered_image=ThreshoBlob(imgray3,imlistCon,fn,thr_value2,max_area,edge_margin,showing,ImageSaveFolder)\n",
    "        if labelR != \"\" and len(imlistCon)==len(imlist2Con):\n",
    "            imn2=imlist2Con[fn]\n",
    "            im2=matplotlib.pyplot.imread(imn2)\n",
    "            Showim(im2,imlist2Con[fn],showing,ImageSaveFolder)\n",
    "            thresh2,filtered_image=AOIdetector(filtered_image,im2,imn2,edge_margin,Grain,showing,ImageSaveFolder)\n",
    "        image_max,coordinates = FindLocalMax(imgray2,size_value,min_distance_value,threshold_abs_value,edge_margin,showing)\n",
    "        thresh=threshold(imgray2,imlistCon,fn,thr_value2,Blocksize,Constant,edge_margin,filtered_image,showing,ImageSaveFolder)\n",
    "        labels,IDs,Areas,coordinates,contour_list,new_cmap,xs,ys,Centers,Ferets,angles=coords(imlistCon,fn,thresh,coordinates,imgray3,min_thresh_counter,showing,ImageSaveFolder)\n",
    "        nearest_neighbors=nearest_neighbor_kd_tree(Centers)\n",
    "        if Spatial==True:\n",
    "            geary, geary_interpretation=calculate_geary_c_from_centroids_and_ferets(Centers,Ferets)\n",
    "            voronoi_diagram(Centers, ImageSaveFolder, showing)\n",
    "            morans_i_value, Moran_interpretation= morans_i(Centers, Areas)\n",
    "            ripleys_k_function(Centers, 600, 100, showing, ImageSaveFolder)\n",
    "        else:\n",
    "            geary, geary_interpretation,morans_i_value, Moran_interpretation = None, \"None\", None, \"None\"\n",
    "        AreaperFieldporcent, AnalyzedArea=analyze_area_coverage(filtered_image, Areas)\n",
    "        avAreas,STDAreas,NAreas,_,_,_=estadisticas(Areas)\n",
    "        avMferet,STDMferet,NMferet,_,_,_=estadisticas([feret[0] for feret in Ferets])\n",
    "        avmferet,STDmferet,Nmferet,_,_,_=estadisticas([feret[1] for feret in Ferets])\n",
    "        avAng,STDAng,NAng,_,_,_=estadisticas(angles)\n",
    "        avNN,STDNN,NNN,_,_,_=estadisticas([nn[2] for nn in nearest_neighbors])\n",
    "        DF=TextOutput(fn,contour_list,IDs,Areas,coordinates,xs,ys,Centers,Ferets,angles,imlistCon,impath,csvSaveFolder)\n",
    "        DF2=pandas.DataFrame({\"ID\":[imn.split(\"/\")[-1]],\n",
    "                            \"Area per colony Average [px]\": [avAreas],\n",
    "                            \"Area per colony Standard deviation [px]\": [STDAreas],\n",
    "                            \"Number of colonies\": [NAreas],\n",
    "                            \"Major Feret Average [px]\": [avMferet],\n",
    "                            \"Major Feret Standard deviation [px]\": [STDMferet],\n",
    "                            \"Minor Feret Average [px]\": [avmferet],\n",
    "                            \"Minor Feret Standard deviation\": [STDmferet],\n",
    "                            \"Angles Average\": [avAng],\n",
    "                            \"Angles Standard deviation\": [STDAng],\n",
    "                            \"Nearest neighbor Average [px]\": [avNN],\n",
    "                            \"Nearest neighbor Standard deviation [px]\": [STDNN],\n",
    "                            \"Area Colonized [%]\": [AreaperFieldporcent],\n",
    "                            \"Area Analyzed [px]\": [AnalyzedArea],\n",
    "                            \"Geary's C\": [geary],\n",
    "                            \"Geary's C interpetration\": [geary_interpretation],\n",
    "                            \"Moran's I\": [morans_i_value],\n",
    "                            \"Moran's I interpetration\": [Moran_interpretation],\n",
    "                            \"Ripley's K\": [ripleys_k_function]})\n",
    "        #os.makedirs(imlistCon[fn].replace(impath,csvSaveFolder).replace(\"\\\\\",\"/\").replace((imlistCon[fn].split(\"\\\\\"))[-1],\"\"), exist_ok=True)\n",
    "        file_path = os.path.join(csvSaveFolder, Cond)+\".csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            existing_df = pandas.read_csv(file_path)\n",
    "            combined_df = pandas.concat([existing_df, DF2], ignore_index=True)\n",
    "            combined_df.to_csv(file_path, index=False)\n",
    "        else:\n",
    "            DF2.to_csv(file_path, index=False)\n",
    "        print(DF2)\n",
    "        return(DF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35137b8b-62e8-45cc-94aa-7fae13fdac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runMany(\n",
    "    impath,\n",
    "    labelsD,\n",
    "    labelR,\n",
    "    imlabel,\n",
    "    BadLabel,\n",
    "    ImageSaveFolder,\n",
    "    csvSaveFolder,\n",
    "    Cond=\"\",\n",
    "    Grain=False,\n",
    "    blur_threshold=100, \n",
    "    max_area=50*50*numpy.pi,\n",
    "    contrast_threshold=50,\n",
    "    edge_margin=10,\n",
    "    rad=50,\n",
    "    thr_value2=100,\n",
    "    size_value=2,\n",
    "    min_distance_value=2,\n",
    "    min_thresh_counter=4,\n",
    "    threshold_abs_value=0.1,\n",
    "    Blocksize=15,\n",
    "    Constant=-1,\n",
    "    showing=True,\n",
    "    QualityCheck=False,\n",
    "    Reverse=True,\n",
    "    Spatial=True\n",
    "):\n",
    "    if Cond==\"\":\n",
    "        Conds=[]\n",
    "        for Folder in [x for x in os.listdir(impath) if os.path.isdir(os.path.join(impath,x))]:\n",
    "            Conds += [Folder]\n",
    "    else:\n",
    "        Conds=[Cond]\n",
    "    imlist=[]\n",
    "    imlist2=[]\n",
    "    for label in labelsD:\n",
    "        if Reverse==True:\n",
    "            Conds.reverse\n",
    "        for Cond in Conds:\n",
    "            for (root,dirs,files) in os.walk(impath, topdown=True):\n",
    "                for file in files:\n",
    "                    if not file.endswith(imlabel):\n",
    "                        continue\n",
    "                    if label in file:\n",
    "                        imlist += [os.path.join(root,file)]\n",
    "                    if labelR in file:\n",
    "                        imlist2 += [os.path.join(root,file)]\n",
    "            imlistCon=[f for f in imlist if Cond in f]\n",
    "            imlist2Con=[f for f in imlist2 if Cond in f]\n",
    "            if Reverse==True:\n",
    "                imlistCon.reverse\n",
    "                imlist2Con.reverse\n",
    "            for fn in range(len(imlistCon)):\n",
    "                print(str(fn)+\"/\"+str(len(imlistCon)))\n",
    "                # Verificar si la imagen ya ha sido analizada antes de comenzar\n",
    "                if has_been_analyzed(impath, csvSaveFolder, fn, imlistCon) == True:\n",
    "                    print(f\"El archivo {imlistCon[fn]} ya ha sido analizado. Omite el análisis.\")\n",
    "                    continue  # Omite el procesamiento de esta imagen\n",
    "                imn=imlistCon[fn]\n",
    "                im=matplotlib.pyplot.imread(imn)\n",
    "                if showing==True:\n",
    "                    print(\"Starting analysis of image: \"+imn)\n",
    "                    Showim(im,imlistCon[fn],showing,ImageSaveFolder)\n",
    "                #Process image 1\n",
    "                imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) #threshold\n",
    "                if showing == True:\n",
    "                    print(\"Gray\")\n",
    "                    Showim(imgray,\"/Dye\"+imlistCon[fn],showing,ImageSaveFolder)\n",
    "                imgray2=imgray\n",
    "                if QualityCheck==True:\n",
    "                    quality=check_image_quality(imgray2, blur_threshold, contrast_threshold)\n",
    "                else:\n",
    "                    quality=True\n",
    "                if quality==True:\n",
    "                    imgray,imgray2,imgray3=backgroundrolling(im,rad,imlistCon,fn,showing,ImageSaveFolder=\"\")\n",
    "                    thresh,filtered_image=ThreshoBlob(imgray3,imlistCon,fn,thr_value2,max_area,edge_margin,showing,ImageSaveFolder)\n",
    "                    if labelR != \"\" and len(imlistCon)==len(imlist2Con):\n",
    "                        imn2=imlist2Con[fn]\n",
    "                        im2=matplotlib.pyplot.imread(imn2)\n",
    "                        Showim(im2,imlist2Con[fn],showing,ImageSaveFolder)\n",
    "                        thresh2,filtered_image=AOIdetector(filtered_image,im2,imn2,edge_margin,Grain,showing,ImageSaveFolder)\n",
    "                    image_max,coordinates = FindLocalMax(imgray2,size_value,min_distance_value,threshold_abs_value,edge_margin,showing)\n",
    "                    thresh=threshold(imgray2,imlistCon,fn,thr_value2,Blocksize,Constant,edge_margin,filtered_image,showing,ImageSaveFolder)\n",
    "                    labels,IDs,Areas,coordinates,contour_list,new_cmap,xs,ys,Centers,Ferets,angles=coords(imlistCon,fn,thresh,coordinates,imgray3,min_thresh_counter,showing,ImageSaveFolder)\n",
    "                    nearest_neighbors=nearest_neighbor_kd_tree(Centers)\n",
    "                    if spatial==True:\n",
    "                        geary, geary_interpretation=calculate_geary_c_from_centroids_and_ferets(Centers,Ferets)\n",
    "                        voronoi_diagram(Centers, ImageSaveFolder, showing)\n",
    "                        morans_i_value, Moran_interpretation= morans_i(Centers, Areas)\n",
    "                        ripleys_k_function(Centers, 600, 100, showing, ImageSaveFolder)\n",
    "                    else:\n",
    "                        geary, geary_interpretation,morans_i_value, Moran_interpretation = None, \"None\", None, \"None\"\n",
    "                    AreaperFieldporcent, AnalyzedArea=analyze_area_coverage(filtered_image, Areas)\n",
    "                    avAreas,STDAreas,NAreas,_,_,_=estadisticas(Areas)\n",
    "                    avMferet,STDMferet,NMferet,_,_,_=estadisticas([feret[0] for feret in Ferets])\n",
    "                    avmferet,STDmferet,Nmferet,_,_,_=estadisticas([feret[1] for feret in Ferets])\n",
    "                    avAng,STDAng,NAng,_,_,_=estadisticas(angles)\n",
    "                    avNN,STDNN,NNN,_,_,_=estadisticas([nn[2] for nn in nearest_neighbors])\n",
    "                    DF=TextOutput(fn,contour_list,IDs,Areas,coordinates,xs,ys,Centers,Ferets,angles,imlistCon,impath,csvSaveFolder)\n",
    "                    DF2=pandas.DataFrame({\"ID\":[imn.split(\"/\")[-1]],\n",
    "                                        \"Area per colony Average [px]\": [avAreas],\n",
    "                                        \"Area per colony Standard deviation [px]\": [STDAreas],\n",
    "                                        \"Number of colonies\": [NAreas],\n",
    "                                        \"Major Feret Average [px]\": [avMferet],\n",
    "                                        \"Major Feret Standard deviation [px]\": [STDMferet],\n",
    "                                        \"Minor Feret Average [px]\": [avmferet],\n",
    "                                        \"Minor Feret Standard deviation\": [STDmferet],\n",
    "                                        \"Angles Average\": [avAng],\n",
    "                                        \"Angles Standard deviation\": [STDAng],\n",
    "                                        \"Nearest neighbor Average [px]\": [avNN],\n",
    "                                        \"Nearest neighbor Standard deviation [px]\": [STDNN],\n",
    "                                        \"Area Colonized [%]\": [AreaperFieldporcent],\n",
    "                                        \"Area Analyzed [px]\": [AnalyzedArea],\n",
    "                                        \"Geary's C\": [geary],\n",
    "                                        \"Geary's C interpetration\": [geary_interpretation],\n",
    "                                        \"Moran's I\": [morans_i_value],\n",
    "                                        \"Moran's I interpetration\": [Moran_interpretation],\n",
    "                                        \"Ripley's K\": [ripleys_k_function]})\n",
    "                    #os.makedirs(imlistCon[fn].replace(impath,csvSaveFolder).replace(\"\\\\\",\"/\").replace((imlistCon[fn].split(\"\\\\\"))[-1],\"\"), exist_ok=True)\n",
    "                    file_path = os.path.join(csvSaveFolder, Cond)+\".csv\"\n",
    "                    if os.path.exists(file_path):\n",
    "                        existing_df = pandas.read_csv(file_path)\n",
    "                        combined_df = pandas.concat([existing_df, DF2], ignore_index=True)\n",
    "                        combined_df.to_csv(file_path, index=False)\n",
    "                        DF2=combined_df\n",
    "                    else:\n",
    "                        DF2.to_csv(file_path, index=False)\n",
    "            \n",
    "            file_path = os.path.join(csvSaveFolder, Cond)+\".csv\"\n",
    "            if os.path.exists(file_path):\n",
    "                existing_df = pandas.read_csv(file_path)\n",
    "                DF2=existing_df\n",
    "    return(DF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63b3b4-6c37-4992-a15a-98adba6f232b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Función para calcular el coeficiente de variación\n",
    "def coeficiente_de_variacion(datos):\n",
    "    \"\"\"\n",
    "    Calcula el Coeficiente de Variación (CV) de una lista de datos.\n",
    "    El Coeficiente de Variación se calcula como (desviación estándar / media) * 100.\n",
    "    \n",
    "    :param datos: Lista de datos numéricos\n",
    "    :return: Coeficiente de variación\n",
    "    \"\"\"\n",
    "    media = numpy.mean(datos)\n",
    "    desviacion_estandar = numpy.std(datos)\n",
    "    \n",
    "    if media != 0:\n",
    "        cv = (desviacion_estandar / media) * 100\n",
    "    else:\n",
    "        cv = 0  # Si la media es 0, el CV es 0 (caso límite)\n",
    "    \n",
    "    return cv\n",
    "\n",
    "\n",
    "# Asegurarse de que la columna 'Colony Density [mm^-2]' exista en el CSV\n",
    "def List_CV(csv_file,namecol):\n",
    "    csv = pandas.read_csv(csv_file)\n",
    "    try:\n",
    "        if namecol in csv.columns:\n",
    "            #print(csv)\n",
    "            return csv[namecol].dropna().tolist()\n",
    "        else:\n",
    "            return []\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: El archivo {csv_file} está vacío.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el archivo {csv_file}: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "def CV_rep(datos, csv_file, size=2, groups=3, reps=25):\n",
    "    datos=List_CV(csv_file,\"Number of colonies\")\n",
    "    if not len(datos) >= size*groups:\n",
    "        print(\"not enough data\")\n",
    "        return[]\n",
    "    else:\n",
    "        CVs=[]\n",
    "        for x in range(reps):\n",
    "            #make groups of size to calculate CV.\n",
    "            ranNums = random.sample(datos, size*groups)\n",
    "            #print(ranNums)\n",
    "            mean_group=[]\n",
    "            for n in range(groups):\n",
    "                group=ranNums[(n)*size:(n+1)*size]\n",
    "                #print(ranNums[(n)*size:(n+1)*size])\n",
    "                #Calcular promedio y std de cada grupo de datos\n",
    "                mean_group.append(statistics.mean(group))\n",
    "            #calcula CV\n",
    "            mean_dat=statistics.mean(mean_group)\n",
    "            std_dat=statistics.stdev(mean_group)\n",
    "            CV_dat=(std_dat/mean_dat)*100\n",
    "            CVs.append(CV_dat)\n",
    "            #print(str(x+1)+\": \"+str(CV_dat))\n",
    "        return(CVs)\n",
    "\n",
    "def CV(Cond,csvSaveFolder,dana=\"Number of colonies\",groups=3,reps=25):\n",
    "    print(Cond)\n",
    "    csv_file = os.path.join(csvSaveFolder, Cond)+\".csv\"\n",
    "    sizes=[1,2,3,6,9,12,18,27,30,36,72,96,120]\n",
    "    datos=List_CV(csv_file,dana)\n",
    "    #print(len(datos))\n",
    "    #print(datos)\n",
    "    cv_dict = {}\n",
    "    for size in sizes:\n",
    "        print(\"size: \"+str(size))\n",
    "        CV_dat=CV_rep(datos,csv_file,size, groups, reps)\n",
    "        if not CV_dat==[]:\n",
    "            cv_dict[size] = CV_dat\n",
    "    saveCV=os.path.join(csvSaveFolder,\"CV-\"+dana+\"-\"+Cond)\n",
    "    pandas.DataFrame(cv_dict).to_csv(saveCV, index=False)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343bb31-5d78-4b96-b9d9-ea2affa4acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_parameters_to_csv_dynamic(\n",
    "    labelsD, labelR, imlabel, BadLabel,\n",
    "    impath, ImageSaveFolder, csvSaveFolder,\n",
    "    pixeltoum, AreaperField, squaredPixel,\n",
    "    intersection_threshold, x, showing,\n",
    "    minArea, maxArea, cheackarea, Grain,\n",
    "    thr_value2, min_thresh_counter, max_area,\n",
    "    edge_margin, rad, size_value, min_distance_value,\n",
    "    threshold_abs_value, Blocksize, Constant,\n",
    "    QualityCheck, blur_threshold, contrast_threshold\n",
    "):\n",
    "    # Create directories if they don't exist\n",
    "    if not os.path.exists(ImageSaveFolder):\n",
    "        os.makedirs(ImageSaveFolder)\n",
    "    if not os.path.exists(csvSaveFolder):\n",
    "        os.makedirs(csvSaveFolder)\n",
    "\n",
    "    # Create the parameters dictionary\n",
    "    params = {\n",
    "        \"labelsD\": labelsD,\n",
    "        \"labelR\": labelR,\n",
    "        \"imlabel\": imlabel,\n",
    "        \"BadLabel\": BadLabel,\n",
    "        \"impath\": impath,\n",
    "        \"ImageSaveFolder\": ImageSaveFolder,\n",
    "        \"csvSaveFolder\": csvSaveFolder,\n",
    "        \"pixeltoum\": pixeltoum,\n",
    "        \"AreaperField\": AreaperField,\n",
    "        \"squaredPixel\": squaredPixel,\n",
    "        \"intersection_threshold\": intersection_threshold,\n",
    "        \"x\": x,\n",
    "        \"showing\": showing,\n",
    "        \"minArea\": minArea,\n",
    "        \"maxArea\": maxArea,\n",
    "        \"cheackarea\": cheackarea,\n",
    "        \"Grain\": Grain,\n",
    "        \"thr_value2\": thr_value2,\n",
    "        \"min_thresh_counter\": min_thresh_counter,\n",
    "        \"max_area\": max_area,\n",
    "        \"edge_margin\": edge_margin,\n",
    "        \"rad\": rad,\n",
    "        \"size_value\": size_value,\n",
    "        \"min_distance_value\": min_distance_value,\n",
    "        \"threshold_abs_value\": threshold_abs_value,\n",
    "        \"Blocksize\": Blocksize,\n",
    "        \"Constant\": Constant,\n",
    "        \"QualityCheck\": QualityCheck,\n",
    "        \"blur_threshold\": blur_threshold,\n",
    "        \"contrast_threshold\": contrast_threshold\n",
    "    }\n",
    "\n",
    "    # Set CSV file path\n",
    "    csv_file = os.path.join(csvSaveFolder, \"parameters.csv\")\n",
    "\n",
    "    # Save parameters to CSV\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(params.keys())    # Header\n",
    "        writer.writerow(params.values())  # Data\n",
    "\n",
    "    print(f\"Parameters saved to {csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d293b2b-239d-4344-9d16-c4deb8e42a0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812c351-71ad-468d-9e93-b4d5e26c34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsD=[\"DAPI\"]\n",
    "labelR=\"\"\n",
    "imlabel=\".tif\"\n",
    "BadLabel=\"ORG\"\n",
    "impath=\"\"\n",
    "ImageSaveFolder=\"\"\n",
    "csvSaveFolder=\"\"\n",
    "\n",
    "if os.path.exists(ImageSaveFolder)==False:\n",
    "    os.makedirs(ImageSaveFolder)\n",
    "if os.path.exists(csvSaveFolder)==False:\n",
    "    os.makedirs(csvSaveFolder)\n",
    "x=0\n",
    "ntersection_threshold = 0.5\n",
    "showing=True\n",
    "minArea=(2**2)*math.pi\n",
    "maxArea=math.pi*10**2\n",
    "cheackarea=True\n",
    "Grain=False\n",
    "thr_value2 = 100\n",
    "min_thresh_counter=4\n",
    "max_area=maxArea\n",
    "edge_margin=15\n",
    "rad=50\n",
    "size_value=2\n",
    "min_distance_value=2 \n",
    "threshold_abs_value=0.02\n",
    "Blocksize=15\n",
    "Constant=-1\n",
    "intersection_threshold = 0.5  # Ajusta este valor según tu necesidad\n",
    "QualityCheck=False\n",
    "blur_threshold=100\n",
    "contrast_threshold=5\n",
    "showing=True\n",
    "Spatial=True\n",
    "\n",
    "Conds=[]\n",
    "for Folder in [x for x in os.listdir(impath) if os.path.isdir(os.path.join(impath,x))]:\n",
    "    Conds += [Folder]\n",
    "\n",
    "label=labelsD[0]\n",
    "Cond=Conds[0]\n",
    "fn=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c7c0f-02ce-458d-a8a0-c9073aa1f5b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Interact for parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4e268-847c-4fa2-8ec8-b7552a7ecf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.rcParams['figure.figsize'] = [50, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d1610d-be6b-4c27-a00c-406f4237fd27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interact_manual(runSingle,\n",
    "        impath=fixed(impath),\n",
    "        labelsD=fixed(labelsD),\n",
    "        labelR=fixed(labelR),\n",
    "        imlabel=fixed(imlabel),\n",
    "        BadLabel=fixed(BadLabel),\n",
    "        ImageSaveFolder=fixed(ImageSaveFolder),\n",
    "        csvSaveFolder=fixed(csvSaveFolder),\n",
    "        Grain=Grain,\n",
    "        fn=fixed(fn),\n",
    "        label=fixed(label),\n",
    "        Cond=fixed(Cond),\n",
    "        blur_threshold=blur_threshold,\n",
    "        contrast_threshold=contrast_threshold,\n",
    "        edge_margin=edge_margin,\n",
    "        rad=rad,\n",
    "        thr_value2=thr_value2,\n",
    "        max_area=max_area,\n",
    "        size_value=size_value,\n",
    "        min_distance_value=min_distance_value,\n",
    "        threshold_abs_value=threshold_abs_value,\n",
    "        Blocksize=Blocksize,\n",
    "        Constant=Constant,\n",
    "        min_thresh_counter=min_thresh_counter,\n",
    "        QualityCheck=QualityCheck,\n",
    "        showing=fixed(True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995387e-d2be-46dc-9f87-ecebe5d1483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_parameters_to_csv_dynamic(\n",
    "    labelsD, labelR, imlabel, BadLabel,\n",
    "    impath, ImageSaveFolder, csvSaveFolder,\n",
    "    pixeltoum, AreaperField, squaredPixel,\n",
    "    intersection_threshold, x, showing,\n",
    "    minArea, maxArea, cheackarea, Grain,\n",
    "    thr_value2, min_thresh_counter, max_area,\n",
    "    edge_margin, rad, size_value, min_distance_value,\n",
    "    threshold_abs_value, Blocksize, Constant,\n",
    "    QualityCheck, blur_threshold, contrast_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1280d9-2c61-4870-9133-6cfd6733ddc9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "runSingle(impath=impath,\n",
    "        labelsD=labelsD,\n",
    "        labelR=labelR,\n",
    "        imlabel=imlabel,\n",
    "        BadLabel=BadLabel,\n",
    "        ImageSaveFolder=ImageSaveFolder,\n",
    "        csvSaveFolder=csvSaveFolder,\n",
    "        Grain=Grain,\n",
    "        fn=fn,\n",
    "        label=label,\n",
    "        Cond=Cond,\n",
    "        blur_threshold=blur_threshold,\n",
    "        contrast_threshold=contrast_threshold,\n",
    "        edge_margin=edge_margin,\n",
    "        rad=rad,\n",
    "        thr_value2=thr_value2,\n",
    "        max_area=max_area,\n",
    "        size_value=size_value,\n",
    "        min_distance_value=min_distance_value,\n",
    "        threshold_abs_value=threshold_abs_value,\n",
    "        Blocksize=Blocksize,\n",
    "        Constant=Constant,\n",
    "        min_thresh_counter=min_thresh_counter,\n",
    "        QualityCheck=QualityCheck,\n",
    "        showing=True,\n",
    "        Spatial=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d9a48-0ccb-4df6-8f15-03fd1a4a0542",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee59a5-5a9f-4594-b7a7-8123508ab2bb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "runMany(\n",
    "    impath,\n",
    "    labelsD,\n",
    "    labelR,\n",
    "    imlabel,\n",
    "    BadLabel,\n",
    "    ImageSaveFolder,\n",
    "    csvSaveFolder,\n",
    "    \n",
    "    Cond=Conds[3],\n",
    "    Grain=Grain,\n",
    "    blur_threshold=blur_threshold, \n",
    "    max_area=max_area,\n",
    "    contrast_threshold=contrast_threshold,\n",
    "    edge_margin=edge_margin,\n",
    "    rad=rad,\n",
    "    thr_value2=thr_value2,\n",
    "    size_value=size_value,\n",
    "    min_distance_value=min_distance_value,\n",
    "    min_thresh_counter=min_thresh_counter,\n",
    "    threshold_abs_value=threshold_abs_value,\n",
    "    Blocksize=Blocksize,\n",
    "    Constant=Constant,\n",
    "    showing=False,\n",
    "    QualityCheck=QualityCheck,\n",
    "    Reverse=True,\n",
    "    Spatial=Spatial\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048ecd0-77bf-4e95-90b5-1fc2c4d62450",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for Cond in Conds:\n",
    "    print(Cond)\n",
    "    CV(Cond,csvSaveFolder,\"Number of colonies\",3,25)\n",
    "    CV(Cond,csvSaveFolder,\"Area Colonized [%]\",3,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de550d-8100-42fd-983b-6b95a0767f45",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory containing the CSV files\n",
    "input_directory = csvSaveFolder  # Replace with your directory path\n",
    "\n",
    "filename=[filename for filename in os.listdir(csvSaveFolder) if filename.endswith(\".csv\")][0]\n",
    "cols=pandas.read_csv(os.path.join(csvSaveFolder,filename)).columns\n",
    "for col in cols:\n",
    "    condition_dfs=[]\n",
    "    for Con in Conds:\n",
    "        for filename in os.listdir(input_directory):\n",
    "            if filename.endswith(\".csv\") and Cond in filename:\n",
    "                # Read the CSV file\n",
    "                file_path = os.path.join(csvSaveFolder, filename)\n",
    "                df = pandas.read_csv(file_path)\n",
    "                # Extract the condition name from the filename (e.g., 'condition1.csv' -> 'condition1')\n",
    "                condition_name = filename.replace(\"csvSaveFolder\",\"\").replace(\".csv\",\"\")\n",
    "                #print(condition_name)\n",
    "                condition_dfs.append(df[[col]].rename(columns={col: condition_name}))\n",
    "    # Merge all DataFrames on the index (assuming all CSVs have the same index structure)\n",
    "    merged_df = pandas.concat(condition_dfs, axis=1)\n",
    "\n",
    "    # Save the merged DataFrame to a new CSV\n",
    "    output_file = os.path.join(csvSaveFolder,col+\".csv\")  # Desired output file name\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(merged_df)\n",
    "    print(f\"Merged CSV saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4834ecdc-ad11-4a8f-bedb-030a9c2b011d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Parallel run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c036c8a4-c329-4cfe-bcf2-62178131c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecuta una sola vez\n",
    "i = 0\n",
    "totC = 10\n",
    "i*totC+totC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0694675f-015d-414b-b7d0-b6ae4d585271",
   "metadata": {},
   "outputs": [],
   "source": [
    "torun=range(len(Conds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0ccacf-e798-41c7-a33f-2574665d8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FoldersC son las carpetas a ejecutar en cluster paralelos.\n",
    "running = torun[i*totC:i*totC+totC]\n",
    "totC = len(running)\n",
    "i = i+1\n",
    "running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6f80a-01d5-4393-9f31-d29c7a2f784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre Clusters paralelos\n",
    "import ipyparallel as ipp\n",
    "cluster = ipp.Cluster(n=totC)\n",
    "cluster.start_cluster_sync()\n",
    "rc = cluster.connect_client_sync()\n",
    "rc.wait_for_engines(n=totC)\n",
    "print(rc.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7d79f-6b7f-401a-9022-e9be59dc4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rc[:].sync_imports():\n",
    "    import csv\n",
    "    import cv2\n",
    "    import geopandas\n",
    "    import math\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot\n",
    "    import numpy\n",
    "    import os\n",
    "    import pandas\n",
    "\n",
    "    from esda import Moran, Geary\n",
    "    from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "    from libpysal.weights import Queen\n",
    "    from scipy import ndimage\n",
    "    from scipy.spatial import cKDTree, Voronoi, voronoi_plot_2d,distance\n",
    "    from scipy.spatial.distance import cdist\n",
    "    from shapely.geometry import Point\n",
    "    from skimage import restoration, data, img_as_float\n",
    "    from skimage.feature import peak_local_max\n",
    "    from skimage.segmentation import watershed\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6d641-a9e6-42f2-870b-e73491a69f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define las funciones enc ada cluster\n",
    "rc[:].push(dict(\n",
    "    Showim=Showim,\n",
    "    countArray=countArray,\n",
    "    backgroundrolling=backgroundrolling,\n",
    "    FindLocalMax=FindLocalMax,\n",
    "    threshold=threshold,\n",
    "    coords=coords,\n",
    "    TextOutput=TextOutput,\n",
    "    ThreshoBlob=ThreshoBlob,\n",
    "    AOIdetector=AOIdetector,\n",
    "    check_image_quality=check_image_quality,\n",
    "    has_been_analyzed=has_been_analyzed,\n",
    "    voronoi_diagram=voronoi_diagram,\n",
    "    ripleys_k_function=ripleys_k_function,\n",
    "    morans_i=morans_i,\n",
    "    calculate_geary_c_from_centroids_and_ferets=calculate_geary_c_from_centroids_and_ferets,\n",
    "    euclidean_distance=euclidean_distance,\n",
    "    nearest_neighbor_kd_tree=nearest_neighbor_kd_tree,\n",
    "    estadisticas=estadisticas,\n",
    "    analyze_area_coverage=analyze_area_coverage,\n",
    "    runMany=runMany))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434e33d-4dd8-447e-aa95-dfa158e79e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for numb in range(len(running)):\n",
    "    results[numb] = rc[numb].apply_async(runMany,\n",
    "                                         impath, \n",
    "                                         labelsD, \n",
    "                                         labelR,\n",
    "                                         imlabel,\n",
    "                                         BadLabel,\n",
    "                                         ImageSaveFolder,\n",
    "                                         csvSaveFolder,\n",
    "                                         Conds[numb],\n",
    "                                         Grain,\n",
    "                                         blur_threshold,\n",
    "                                         max_area,\n",
    "                                         contrast_threshold,\n",
    "                                         edge_margin,\n",
    "                                         rad,\n",
    "                                         thr_value2,\n",
    "                                         size_value,\n",
    "                                         min_distance_value,\n",
    "                                         min_thresh_counter,\n",
    "                                         threshold_abs_value,\n",
    "                                         Blocksize, \n",
    "                                         Constant,\n",
    "                                         showing,\n",
    "                                         QualityCheck,\n",
    "                                         Spatial)#, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82968ba6-f125-4ff1-aa84-07f2abdf9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indica si los resultados estan listos. ejecuta cuantas veces sea necesario\n",
    "for numb in range(totC):\n",
    "    print('is engine '+str(numb)+' ready?:')\n",
    "    print(results[numb].ready())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb913c64-d49e-421f-bd02-98077327817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisa si ocurrio algun error\n",
    "for num in range(totC):\n",
    "    print('Engine '+str(num)+' ')\n",
    "    try:\n",
    "        results[num].get(1)\n",
    "        print('Results ready without error')\n",
    "        print('')\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22848785-28de-427b-b4ad-a86b20e5b3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332ec724-14c8-47e1-bd9b-2491a8bdb602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f79b6-29c9-4924-a18f-b4e7e77d7871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5446fc-509c-4eff-8578-283f21b730f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
